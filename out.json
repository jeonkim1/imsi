{"apic":{"clusterHealth":{"name":"APIC Cluster Health","state":{"unFit":false},"recommended":{"unFit":false},"actionRecommended":false,"descr":"Check cluster state","meta":{"runTime":"786.42Âµs"}},"infraVLAN":{"name":"Infra VLAN Consistency","state":{"inconsistent":false},"recommended":{"inconsistent":false},"actionRecommended":false,"vlans":["4093"],"descr":"Infra VLAN is consistent across cluster.","meta":{"runTime":"3.15434ms"}}},"health":{"score":{"error":"DB:GET:healthInst:topology/pod-1/node-101/sys/health:not found","meta":{"runTime":"1.663357ms"}}},"scale":{"guide":{"name":"Scalability Guide","state":{},"recommended":{},"descr":"Scalability guide","url":"https://www.cisco.com/c/en/us/td/docs/switches/datacenter/aci/apic/sw/4-x/verified_scalability/Cisco-ACI-Verified-Scalability-Guide-422.html","actionRecommended":false,"meta":{"runTime":"1.518661ms"}},"switch":{"name":"Per-switch Scale","state":{"isOverScale":false},"recommended":{"isOverScale":false},"descr":"Per-device scale metrics","metrics":[{"name":"DC1-LEAF-101","epgs":{"limit":3960,"count":31},"bds":{"limit":3500,"count":28},"vrfs":{"limit":800,"count":26},"tcam":{"limit":65536,"count":57206},"vlans":{"limit":3960,"count":3275},"l2Local":{"limit":24576,"count":93},"l2Remote":{"limit":0,"count":3},"l2Total":{"limit":24576,"count":96},"l3Local":{"limit":24576,"count":59},"l3Remote":{"limit":0,"count":5},"l3Total":{"limit":24576,"count":64}},{"name":"DC1-LEAF-102","epgs":{"limit":3960,"count":30},"bds":{"limit":3500,"count":26},"vrfs":{"limit":800,"count":22},"tcam":{"limit":65536,"count":58055},"vlans":{"limit":3960,"count":3333},"l2Local":{"limit":24576,"count":96},"l2Remote":{"limit":0,"count":0},"l2Total":{"limit":24576,"count":96},"l3Local":{"limit":24576,"count":61},"l3Remote":{"limit":0,"count":2},"l3Total":{"limit":24576,"count":63}},{"name":"DC1-LEAF-103","epgs":{"limit":3960,"count":0},"bds":{"limit":3500,"count":1},"vrfs":{"limit":800,"count":4},"tcam":{"limit":65536,"count":49},"vlans":{"limit":3960,"count":2},"l2Local":{"limit":24576,"count":1},"l2Remote":{"limit":0,"count":0},"l2Total":{"limit":24576,"count":1},"l3Local":{"limit":24576,"count":3},"l3Remote":{"limit":0,"count":0},"l3Total":{"limit":24576,"count":3}},{"name":"DC1-LEAF-104","epgs":{"limit":3960,"count":0},"bds":{"limit":3500,"count":1},"vrfs":{"limit":800,"count":4},"tcam":{"limit":65536,"count":2266},"vlans":{"limit":3960,"count":29},"l2Local":{"limit":24576,"count":1},"l2Remote":{"limit":0,"count":0},"l2Total":{"limit":24576,"count":1},"l3Local":{"limit":24576,"count":3},"l3Remote":{"limit":0,"count":0},"l3Total":{"limit":24576,"count":3}}],"actionRecommended":false,"meta":{"runTime":"3.245033ms"}},"fabric":{"name":"Fabric-side Scale","state":{"isOverScale":false},"recommended":{"isOverScale":false},"descr":"Fabric-wide scale metrics","endpoints":{"limit":225000,"count":93},"epgs":{"limit":15000,"count":59},"bds":{"limit":15000,"count":53},"vrfs":{"limit":3000,"count":31},"tenants":{"limit":3000,"count":26},"contracts":{"limit":10000,"count":52},"filters":{"limit":10000,"count":47},"actionRecommended":false,"meta":{"runTime":"3.482545ms"}}},"access":{"mcpInterface":{"name":"MCP Interface Configuration","descr":"MCP interface-level configuration","state":{"hasDisabled":false},"recommended":{"hasDisabled":false},"actionRecommended":false,"disabledIntProfs":[],"notes":[],"meta":{"runTime":"1.470683ms"}},"overlappingVLANs":{"name":"Overlapping VLANs","descr":"Overlapping VLANs at the Domain and EPG levels.","state":{"hasOverlappingVLANs":true,"hasOverlappingVLANPathBindings":false},"recommended":{"hasOverlappingVLANs":false,"hasOverlappingVLANPathBindings":false},"actionRecommended":true,"overlappingVLANs":[{"domA":"uni/phys-UCS-FI","domB":"uni/phys-accordion-pdom","poolA":"uni/infra/vlanns-[UCS-FI]-dynamic","poolB":"uni/infra/vlanns-[accordion-pool]-static","blocks":[{"from":1102,"to":1102},{"from":1103,"to":1103}]},{"domA":"uni/phys-K8S_Cluster1-pdom","domB":"uni/phys-UCS-FI","poolA":"uni/infra/vlanns-[K8S_Cluster1-pool]-static","poolB":"uni/infra/vlanns-[UCS-FI]-dynamic","blocks":[{"from":1100,"to":1100},{"from":1101,"to":1101}]}],"overlappingVLANPathBindings":[],"meta":{"runTime":"5.567047ms"}}},"fabric":{"routeReflectors":{"name":"Route Reflectors","state":{"hasNonRedundant":false},"recommended":{"hasNonRedundant":false},"actionRecommended":false,"rrsPerPod":{"1":[201,201,202,201,202]},"descr":"Verify every pod has at least 2 route reflectors","meta":{"runTime":"1.33874ms"}},"topology":{"name":"Topology Check","descr":"Verify each Leaf is connected to multiple Spines","leaves":["101","102","103","104"],"spines":["201","202"],"leafLinks":{"101":["201"],"102":["201"],"103":["201"],"104":["201"]},"state":{"numLeavesSingleFailure":4,"leaves":["104","101","102","103"]},"recommended":{"numLeavesSingleFailure":0,"leaves":null},"actionRecommended":true,"meta":{"runTime":"1.868751ms"}},"bfdFabricInt":{"name":"BFD for Fabric Interfaces","descr":"BFD on fabric-facing interfaces","state":{"enabled":true},"recommended":{"enabled":false},"actionRecommended":true,"meta":{"runTime":"1.769005ms"}},"dom":{"name":"Digital Optical Monitoring (DOM)","descr":"Check that DOM is enabled","state":{"disabledCount":1},"recommended":{"disabledCount":0},"disabledNodes":["201"],"actionRecommended":true,"meta":{"runTime":"2.90008ms"}},"isisMetric":{"name":"ISIS Metric","descr":"ISIS default metric for inter-pod routing","state":{"metric":62},"recommended":{"metric":62},"podCount":1,"isMultipod":false,"isPreFix":false,"actionRecommended":false,"notes":[],"meta":{"runTime":"3.321551ms"}},"ntp":{"name":"NTP Configuration","state":{"enabled":true,"neighborCount":1},"recommended":{"enabled":true,"neighborCount":2},"auth":false,"actionRecommended":true,"faults":[],"descr":"NTP config and redudancy check","meta":{"runTime":"1.872134ms"}},"coopStrict":{"name":"COOP Strict Mode","descr":"Check that COOP strict is enabled","state":{"enabled":false},"recommended":{"enabled":true},"actionRecommended":true,"meta":{"runTime":"3.519889ms"}},"fn72145":{"name":"Check for FN72145","descr":"SSD failure after 3.2 years of power on hours","state":{"isImpacted":false},"recommended":{"isImpacted":false},"impactedDevices":[],"actionRecommended":false,"meta":{"runTime":"3.618421ms"}},"mcpGlobal":{"name":"MCP Global Configuration","descr":"Check that MCP is enabled globaly","state":{"enabled":true,"pduPerVLAN":false},"recommended":{"enabled":true,"pduPerVLAN":true},"notes":[],"actionRecommended":true,"meta":{"runTime":"4.258533ms"}}},"stats":{"fabricStats":{"name":"Fabric Statistics","state":{},"recommended":{},"descr":"Fabric statistics","controllers":[{"model":"APIC-SERVER-M2","count":3}],"leaves":[{"model":"N9K-C93180YC-EX","count":2},{"model":"N9K-C9348GC-FXP","count":2}],"spines":[{"model":"N9K-C9364C","count":2}],"actionRecommended":false,"meta":{"runTime":"1.950755ms"}},"multipod":{"name":"Multipod","state":{},"recommended":{},"podCount":1,"isMultipod":false,"actionRecommended":false,"descr":"Check if fabric is multipod","meta":{"runTime":"2.233036ms"}},"inventory":{"name":"Fabric Statistics","state":{},"recommended":{},"descr":"Fabric statistics","devices":[{"fabricDomain":"DC1","oobMgmtAddr":"10.70.136.21","inbMgmtAddr":"192.168.7.21","role":"controller","podId":"1","id":"1","version":"5.2(3g)","name":"DC1-APIC1","serial":"FCH2226VKNS"},{"fabricDomain":"DC1","oobMgmtAddr":"10.70.136.26","inbMgmtAddr":"192.168.7.31","role":"leaf","podId":"1","id":"101","version":"n9000-15.2(3g)","name":"DC1-LEAF-101","serial":"FDO21362J28"},{"fabricDomain":"DC1","oobMgmtAddr":"10.70.136.27","inbMgmtAddr":"192.168.7.32","role":"leaf","podId":"1","id":"102","version":"n9000-15.2(3g)","name":"DC1-LEAF-102","serial":"FDO213824YW"},{"fabricDomain":"DC1","oobMgmtAddr":"10.70.136.28","inbMgmtAddr":"192.168.7.33","role":"leaf","podId":"1","id":"103","version":"n9000-15.2(3g)","name":"DC1-LEAF-103","serial":"FDO21420S7G"},{"fabricDomain":"DC1","oobMgmtAddr":"10.70.136.29","inbMgmtAddr":"192.168.7.34","role":"leaf","podId":"1","id":"104","version":"n9000-15.2(3g)","name":"DC1-LEAF-104","serial":"FDO2339094P"},{"fabricDomain":"DC1","oobMgmtAddr":"10.70.136.22","inbMgmtAddr":"192.168.7.22","role":"controller","podId":"1","id":"2","version":"5.2(3g)","name":"DC1-APIC2","serial":"FCH2226VKNR"},{"fabricDomain":"DC1","oobMgmtAddr":"10.70.136.24","inbMgmtAddr":"192.168.7.41","role":"spine","podId":"1","id":"201","version":"n9000-15.2(3g)","name":"DC1-SPINE-201","serial":"FDO21372ZVM"},{"fabricDomain":"DC1","oobMgmtAddr":"10.70.136.23","inbMgmtAddr":"192.168.7.23","role":"controller","podId":"1","id":"3","version":"5.2(3g)","name":"DC1-APIC3","serial":"FCH2226VKGN"}],"actionRecommended":false,"meta":{"runTime":"3.807517ms"}}},"system":{"rogueEPControl":{"name":"Rogue EP Control","descr":"Check for Rogue EP Control","state":{"enabled":false,"multiplier":4},"recommended":{"enabled":true,"multiplier":6},"actionRecommended":true,"detectInterval":60,"holdInterval":1800,"notes":["Exercise caution enabling Rogue EP control"],"meta":{"runTime":"2.083466ms"}},"epLoopProtection":{"name":"EP Loop Protection","descr":"Check for endpoint loop protection","state":{"enabled":false},"recommended":{"enabled":false},"actionRecommended":false,"interval":60,"multiplier":4,"meta":{"runTime":"2.178072ms"}},"encryptedBackups":{"name":"Encrypted Backups","descr":"Encrypted backups should be enabled","state":{"enabled":true},"recommended":{"enabled":true},"actionRecommended":false,"meta":{"runTime":"1.450375ms"}},"domainValidation":{"name":"Domain Validation","descr":"Check if domain validation is enabled","state":{"enabled":true},"recommended":{"enabled":true},"actionRecommended":false,"meta":{"runTime":"1.589852ms"}},"enforceSubnetCheck":{"name":"Enforce Subnet Check","descr":"Check enforce subnet (global setting)","state":{"enabled":true},"recommended":{"enabled":true},"actionRecommended":false,"notes":[],"meta":{"runTime":"3.649325ms"}},"portTracking":{"name":"Port Tracking","descr":"Check if port tracking is enabled","state":{"enabled":false},"recommended":{"enabled":true},"actionRecommended":true,"minLinks":0,"meta":{"runTime":"3.256509ms"}},"ipAging":{"name":"IP Aging","descr":"Check for IP aging","state":{"enabled":true},"recommended":{"enabled":true},"actionRecommended":false,"meta":{"runTime":"3.535373ms"}},"remoteEPlearning":{"name":"Disable Remote EP Learning","descr":"Check state of disable remote EP learning","state":{"on":true},"recommended":{"on":false},"actionRecommended":true,"notes":[],"meta":{"runTime":"3.779142ms"}}},"tenant":{"l3outCSCvh02653":{"name":"CSCvh02653","descr":"Check for CSCvh02653 exposure.","state":{"overlappingSubnets":[]},"recommended":{"overlappingSubnets":[]},"actionRecommended":false,"notes":["Skipped check due to 5.2(3g) not vulnerable."],"meta":{"runTime":"2.722148ms"}},"ingressPolicyEnforcement":{"name":"Ingress Policy Enforcement","descr":"Check that VRFs use ingress policy enforcement","state":{"egressCount":0},"recommended":{"egressCount":0},"egressVRFs":[],"actionRecommended":false,"meta":{"runTime":"2.629347ms"}},"l3outSubnets":{"name":"L3out, BD, and EPG Overlapping Subnets","state":{"hasOverlappingSubnets":true},"recommended":{"hasOverlappingSubnets":false},"overlappingSubnets":[{"epgOrBDdn":"uni/tn-Test_TN/BD-Client/subnet-[100.100.100.1","l3outDN":"uni/tn-0615_Lab/out-L3out"},{"epgOrBDdn":"uni/tn-CISKOLAB/BD-CLIENT/subnet-[10.10.10.1","l3outDN":"uni/tn-Test_TN/out-L3out"}],"actionRecommended":true,"descr":"Check for overlapping subnets between BD, EPG, and l3Out","meta":{"runTime":"4.250248ms"}},"l3outRedundancy":{"name":"L3out Redundancy","descr":"L3outs are deployed across more than one node","state":{"hasNonRedundantL3outs":true},"recommended":{"hasNonRedundantL3outs":false},"nonRedundantL3outCount":5,"nonRedundantL3outs":[{"tenant":"0615_Lab","l3out":"L3out"},{"tenant":"KHNP_DC1","l3out":"KHNP_L4Out"},{"tenant":"Tenant_L3Out","l3out":"L3Out"},{"tenant":"infra","l3out":"intersite"},{"tenant":"mgmt","l3out":"INB-L3Out"}],"actionRecommended":true,"meta":{"runTime":"3.036042ms"}},"commonTenantDuplicates":{"name":"Common Tenant Naming Conflicts","state":{"hasDuplicates":true},"recommended":{"hasDuplicates":false},"actionRecommended":true,"descr":"Duplicate object names between common and user tenants.","dupBDs":[],"dupVRFs":[],"dupFilters":["uni/tn-CISKOLAB/flt-default","uni/tn-cs-demo-shinsaegae/flt-icmp"],"dupContracts":[],"meta":{"runTime":"3.672663ms"}},"vzAny":{"name":"vzAny Configuration","descr":"Check for opportunities to use vzAny","state":{"ubiqitousContractCount":7},"recommended":{"ubiqitousContractCount":0},"contracts":[{"tenant":"Ansible_kwakim","vrf":"A","contract":"uni/tn-common/brc-DC1-L3Out-ASA"},{"tenant":"KHNP_DC1","vrf":"VRF1","contract":"uni/tn-common/brc-GJ-DJ_Cont"},{"tenant":"KHNP_DC1","vrf":"VRF2","contract":"uni/tn-common/brc-GJ-DJ_Cont"},{"tenant":"Labtest_seulee","vrf":"A","contract":"uni/tn-common/brc-DC1-L3Out-ASA"},{"tenant":"NHF_jeonkim","vrf":"a","contract":"uni/tn-common/brc-DC1-L3Out-ASA"},{"tenant":"Test-Coupang_bokoo","vrf":"A","contract":"uni/tn-common/brc-DC1-L3Out-ASA"},{"tenant":"insekimdev","vrf":"demo","contract":"ANY_CT"}],"actionRecommended":false,"meta":{"runTime":"4.060072ms"}},"bdStats":{"name":"Bridge Domain Config","descr":"BD statistics and configuration checks","state":{"noARPGlean":1,"ipLearnFlood":2,"floodInEncapProxy":0,"cscvh17285":0},"recommended":{"noARPGlean":0,"ipLearnFlood":0,"floodInEncapProxy":0,"cscvh17285":0},"stats":{"total":49,"l2":2,"l2Proxy":1,"l2Flood":1,"l3":47,"l3Flood":6,"l3Proxy":41,"l3NoSubnet":4,"l3LimitIPLearn":0},"noARPGlean":{"count":1,"name":["my_shared_bd"]},"floodInEncap":{"count":2,"name":["BD_110","BD_111"]},"ipLearnFlood":{"count":2,"name":["K8S_Cluster1_bd_kubernetes-service","accordion_bd_kubernetes-service"]},"floodInEncapProxy":{"count":0,"name":[]},"cscvh17285":{"count":0,"name":[]},"actionRecommended":true,"meta":{"runTime":"5.715601ms"}},"bdVRFAssociation":{"name":"BD to VRF Associations","state":{"hasInvalidAssociations":true},"recommended":{"hasInvalidAssociations":false},"actionRecommended":true,"invalidAssociations":[{"bd":"uni/tn-CISKOLAB/BD-aci-containers-K8S_Cluster1-node-bd","configuredAssoc":"uni/tn-CISKOLAB/ctx-L3Out"},{"bd":"uni/tn-CISKOLAB/BD-aci-containers-K8S_Cluster1-pod-bd","configuredAssoc":"uni/tn-CISKOLAB/ctx-L3Out"},{"bd":"uni/tn-common/BD-K8S_Cluster1_bd_kubernetes-service","configuredAssoc":"uni/tn-common/ctx-L3Out"},{"bd":"uni/tn-common/BD-default","configuredAssoc":"uni/tn-common/ctx-L3Out"}],"descr":"Empty, non-existent, or invalid VRF association in BD","meta":{"runTime":"5.82085ms"}},"stats":{"name":"Per-Tenant Statistics","state":{},"recommended":{},"descr":"Per-tenant statistics","statsByTenant":[{"name":"0615_Lab","vrfCount":3,"bdCount":2,"contractCount":3,"epgCount":2,"l3outCount":1},{"name":"ACIHealthCheck_jeonkim","vrfCount":2,"bdCount":5,"contractCount":3,"epgCount":3,"l3outCount":0},{"name":"Ansible_kwakim","vrfCount":1,"bdCount":1,"contractCount":0,"epgCount":1,"l3outCount":0},{"name":"CISKOLAB","vrfCount":1,"bdCount":11,"contractCount":10,"epgCount":15,"l3outCount":0},{"name":"KHNP_DC1","vrfCount":2,"bdCount":4,"contractCount":0,"epgCount":4,"l3outCount":1},{"name":"Labtest_seulee","vrfCount":1,"bdCount":1,"contractCount":0,"epgCount":1,"l3outCount":0},{"name":"NHF_jeonkim","vrfCount":1,"bdCount":1,"contractCount":0,"epgCount":1,"l3outCount":0},{"name":"TEST_Tenant","vrfCount":0,"bdCount":0,"contractCount":0,"epgCount":0,"l3outCount":0},{"name":"Tenant_L3Out","vrfCount":1,"bdCount":0,"contractCount":0,"epgCount":0,"l3outCount":1},{"name":"Tenant_ServerFarm","vrfCount":1,"bdCount":2,"contractCount":2,"epgCount":2,"l3outCount":0},{"name":"Test","vrfCount":1,"bdCount":2,"contractCount":1,"epgCount":4,"l3outCount":0},{"name":"Test-Coupang_bokoo","vrfCount":1,"bdCount":1,"contractCount":0,"epgCount":1,"l3outCount":0},{"name":"Test_TN","vrfCount":1,"bdCount":4,"contractCount":2,"epgCount":4,"l3outCount":1},{"name":"Test_suwoo","vrfCount":1,"bdCount":1,"contractCount":0,"epgCount":2,"l3outCount":0},{"name":"aaa_test","vrfCount":0,"bdCount":0,"contractCount":0,"epgCount":0,"l3outCount":0},{"name":"accordion","vrfCount":0,"bdCount":2,"contractCount":6,"epgCount":5,"l3outCount":0},{"name":"common","vrfCount":4,"bdCount":4,"contractCount":16,"epgCount":1,"l3outCount":3},{"name":"cs-demo-SSG","vrfCount":1,"bdCount":2,"contractCount":1,"epgCount":2,"l3outCount":0},{"name":"cs-demo-STARBS","vrfCount":1,"bdCount":2,"contractCount":1,"epgCount":2,"l3outCount":0},{"name":"cs-demo-k8s","vrfCount":1,"bdCount":0,"contractCount":1,"epgCount":0,"l3outCount":1},{"name":"cs-demo-shinsaegae","vrfCount":1,"bdCount":1,"contractCount":1,"epgCount":0,"l3outCount":1},{"name":"infra","vrfCount":2,"bdCount":2,"contractCount":0,"epgCount":2,"l3outCount":2},{"name":"insekimdev","vrfCount":1,"bdCount":1,"contractCount":1,"epgCount":1,"l3outCount":0},{"name":"kylim-test","vrfCount":1,"bdCount":2,"contractCount":1,"epgCount":4,"l3outCount":0},{"name":"mgmt","vrfCount":2,"bdCount":1,"contractCount":3,"epgCount":2,"l3outCount":1},{"name":"my_shared_tenant","vrfCount":0,"bdCount":1,"contractCount":0,"epgCount":0,"l3outCount":0}],"actionRecommended":false,"meta":{"runTime":"8.971632ms"}}},"faults":{"ssd":{"name":"SSD faults","descr":"APIC and switch SSD faults","faults":{},"state":{"apicFaultCount":0,"switchFaultCount":0},"recommended":{"apicFaultCount":0,"switchFaultCount":0},"actionRecommended":false,"meta":{"runTime":"3.293832ms"}},"critical":{"name":"High-Risk Faults","descr":"Check for high-risk faults","state":{"faultCount":2},"recommended":{"faultCount":0},"actionRecommended":true,"faults":{"F0467":[{"code":"F0467","dn":"topology/pod-1/node-101/local/svc-policyelem-id-0/uni/epp/rtd-[uni/tn-cs-demo-shinsaegae/out-Calico/instP-SSG_NS]/nwissues/fault-F0467","descr":"Configuration failed for uni/tn-cs-demo-shinsaegae/out-Calico/instP-SSG_NS due to Prefix Entry Already Used in Another EPG, debug message: prefix-entry-already-in-use: Prefix entry sys/ctx-[vxlan-2883590]/pfx-[100.100.1.0/24] is in use;","ack":"no","severity":"minor"},{"code":"F0467","dn":"topology/pod-1/node-102/local/svc-policyelem-id-0/uni/epp/rtd-[uni/tn-cs-demo-shinsaegae/out-Calico/instP-SSG_NS]/nwissues/fault-F0467","descr":"Configuration failed for uni/tn-cs-demo-shinsaegae/out-Calico/instP-SSG_NS due to Prefix Entry Already Used in Another EPG, debug message: prefix-entry-already-in-use: Prefix entry sys/ctx-[vxlan-2883590]/pfx-[100.100.1.0/24] is in use;","ack":"no","severity":"minor"}]},"meta":{"runTime":"3.650331ms"}},"faults":{"name":"All faults","descr":"All faults for analysis and/or informational purposes","faults":{"F0103":[{"code":"F0103","dn":"topology/pod-1/node-1/sys/cphys-[eth1/2]/fault-F0103","descr":"Physical Interface eth1/2 on Node 1 of fabric DC1 with hostname apic1 is now down","ack":"no","severity":"major"},{"code":"F0103","dn":"topology/pod-1/node-2/sys/cphys-[eth1/2]/fault-F0103","descr":"Physical Interface eth1/2 on Node 2 of fabric DC1 with hostname apic2 is now down","ack":"no","severity":"major"},{"code":"F0103","dn":"topology/pod-1/node-3/sys/cphys-[eth1/2]/fault-F0103","descr":"Physical Interface eth1/2 on Node 3 of fabric DC1 with hostname apic3 is now down","ack":"no","severity":"major"}],"F0132":[{"code":"F0132","dn":"comp/prov-VMware/ctrlr-[DSwitchTest]-vc/fault-F0132","descr":"Operational issues detected for VMM controller: 10.70.136.15 with name vc in datacenter  DC1 in domain: DSwitchTest due to error: Basic Lacp is no longer supported starting DVS 6.6 and above / VC 7.0 (for any DVS version) . Please enable Enhanced Lacp to establish LACP connection.","ack":"no","severity":"major"}],"F0299":[{"code":"F0299","dn":"topology/pod-1/node-101/sys/bgp/inst/dom-Test_TN:VRF/peer-[10.10.10.2/32]/ent-[10.10.10.2]/fault-F0299","descr":"BGP peer is not established, current state Idle","ack":"no","severity":"warning"},{"code":"F0299","dn":"topology/pod-1/node-101/sys/bgp/inst/dom-cs-demo-shinsaegae:VRF01/peer-[100.100.1.11/32]/ent-[100.100.1.11]/fault-F0299","descr":"BGP peer is not established, current state Idle","ack":"no","severity":"warning"},{"code":"F0299","dn":"topology/pod-1/node-101/sys/bgp/inst/dom-cs-demo-shinsaegae:VRF01/peer-[100.100.1.12/32]/ent-[100.100.1.12]/fault-F0299","descr":"BGP peer is not established, current state Idle","ack":"no","severity":"warning"},{"code":"F0299","dn":"topology/pod-1/node-101/sys/bgp/inst/dom-cs-demo-shinsaegae:VRF01/peer-[100.100.1.3/32]/ent-[100.100.1.3]/fault-F0299","descr":"BGP peer is not established, current state Idle","ack":"no","severity":"warning"},{"code":"F0299","dn":"topology/pod-1/node-101/sys/bgp/inst/dom-cs-demo-shinsaegae:VRF01/peer-[100.100.1.4/32]/ent-[100.100.1.4]/fault-F0299","descr":"BGP peer is not established, current state Idle","ack":"no","severity":"warning"},{"code":"F0299","dn":"topology/pod-1/node-101/sys/bgp/inst/dom-cs-demo-shinsaegae:VRF01/peer-[100.100.1.5/32]/ent-[100.100.1.5]/fault-F0299","descr":"BGP peer is not established, current state Idle","ack":"no","severity":"warning"},{"code":"F0299","dn":"topology/pod-1/node-101/sys/bgp/inst/dom-overlay-1/peer-[10.0.136.64/32]/ent-[10.0.136.64]/fault-F0299","descr":"BGP peer is not established, current state Idle","ack":"no","severity":"warning"},{"code":"F0299","dn":"topology/pod-1/node-102/sys/bgp/inst/dom-Test_TN:VRF/peer-[11.11.11.2/32]/ent-[11.11.11.2]/fault-F0299","descr":"BGP peer is not established, current state Idle","ack":"no","severity":"warning"},{"code":"F0299","dn":"topology/pod-1/node-102/sys/bgp/inst/dom-cs-demo-shinsaegae:VRF01/peer-[100.100.1.11/32]/ent-[100.100.1.11]/fault-F0299","descr":"BGP peer is not established, current state Idle","ack":"no","severity":"warning"},{"code":"F0299","dn":"topology/pod-1/node-102/sys/bgp/inst/dom-cs-demo-shinsaegae:VRF01/peer-[100.100.1.12/32]/ent-[100.100.1.12]/fault-F0299","descr":"BGP peer is not established, current state Idle","ack":"no","severity":"warning"},{"code":"F0299","dn":"topology/pod-1/node-102/sys/bgp/inst/dom-cs-demo-shinsaegae:VRF01/peer-[100.100.1.3/32]/ent-[100.100.1.3]/fault-F0299","descr":"BGP peer is not established, current state Idle","ack":"no","severity":"warning"},{"code":"F0299","dn":"topology/pod-1/node-102/sys/bgp/inst/dom-cs-demo-shinsaegae:VRF01/peer-[100.100.1.4/32]/ent-[100.100.1.4]/fault-F0299","descr":"BGP peer is not established, current state Idle","ack":"no","severity":"warning"},{"code":"F0299","dn":"topology/pod-1/node-102/sys/bgp/inst/dom-cs-demo-shinsaegae:VRF01/peer-[100.100.1.5/32]/ent-[100.100.1.5]/fault-F0299","descr":"BGP peer is not established, current state Idle","ack":"no","severity":"warning"},{"code":"F0299","dn":"topology/pod-1/node-102/sys/bgp/inst/dom-overlay-1/peer-[10.0.136.64/32]/ent-[10.0.136.64]/fault-F0299","descr":"BGP peer is not established, current state Idle","ack":"no","severity":"warning"},{"code":"F0299","dn":"topology/pod-1/node-103/sys/bgp/inst/dom-overlay-1/peer-[10.0.136.64/32]/ent-[10.0.136.64]/fault-F0299","descr":"BGP peer is not established, current state Idle","ack":"no","severity":"warning"},{"code":"F0299","dn":"topology/pod-1/node-104/sys/bgp/inst/dom-overlay-1/peer-[10.0.136.64/32]/ent-[10.0.136.64]/fault-F0299","descr":"BGP peer is not established, current state Idle","ack":"no","severity":"warning"},{"code":"F0299","dn":"topology/pod-1/node-201/sys/bgp/inst/dom-overlay-1/peer-[12.12.12.1/32]/ent-[12.12.12.1]/fault-F0299","descr":"BGP peer is not established, current state Idle","ack":"no","severity":"warning"}],"F0413":[{"code":"F0413","dn":"topology/pod-1/node-103/sys/ch/psuslot-2/fault-F0413","descr":"power supply missing","ack":"no","severity":"minor"},{"code":"F0413","dn":"topology/pod-1/node-201/sys/ch/psuslot-2/fault-F0413","descr":"power supply missing","ack":"no","severity":"minor"}],"F0467":[{"code":"F0467","dn":"topology/pod-1/node-101/local/svc-policyelem-id-0/cdef-[uni/tn-common/brc-jeonkim_permitall]/epgCont-[uni/tn-common/ap-jeonkim_common/epg-EPG_Z]/fr-[uni/tn-common/brc-jeonkim_permitall/dirass/cons-[uni/tn-common/ap-jeonkim_common/epg-EPG_Z]-any-no]/to-[uni/tn-common/brc-jeonkim_permitall/any-[uni/tn-ACIHealthCheck_jeonkim/ctx-A/any]-type-prov_as_any/prov-[uni/tn-ACIHealthCheck_jeonkim/ctx-A/any]-any-yes]/nwissues/fault-F0467","descr":"Configuration failed for uni/tn-common/ap-jeonkim_common/epg-EPG_Z due to Invalid Contract Configuration, debug message: invalid-contract-config: Shared service provider cannot be vzAny;","ack":"no","severity":"minor"},{"code":"F0467","dn":"topology/pod-1/node-101/local/svc-policyelem-id-0/uni/epp/br-[uni/tn-kylim-test/l2out-L2out-VLAN10/instP-VLAN10-OUT]/node-101/stpathatt-[eth1/24]/nwissues/fault-F0467","descr":"Configuration failed for uni/tn-kylim-test/l2out-L2out-VLAN10/instP-VLAN10-OUT node 101 eth1/24 due to Invalid Path Configuration, debug message: invalid-path: Either the EpG/L3Out is not associated with a domain or the domain does not have this interface assigned to it;","ack":"no","severity":"minor"},{"code":"F0467","dn":"topology/pod-1/node-101/local/svc-policyelem-id-0/uni/epp/fv-[uni/tn-0615_Lab/ap-Lab/epg-Lab_EPG_1]/node-101/stpathatt-[eth1/39]/nwissues/fault-F0467","descr":"Configuration failed for uni/tn-0615_Lab/ap-Lab/epg-Lab_EPG_1 node 101 eth1/39 due to Invalid Path Configuration, debug message: invalid-path: Either the EpG/L3Out is not associated with a domain or the domain does not have this interface assigned to it;","ack":"no","severity":"minor"},{"code":"F0467","dn":"topology/pod-1/node-101/local/svc-policyelem-id-0/uni/epp/fv-[uni/tn-0615_Lab/ap-Lab/epg-Lab_EPG_2]/node-101/stpathatt-[eth1/39]/nwissues/fault-F0467","descr":"Configuration failed for uni/tn-0615_Lab/ap-Lab/epg-Lab_EPG_2 node 101 eth1/39 due to Invalid Path Configuration, debug message: invalid-path: Either the EpG/L3Out is not associated with a domain or the domain does not have this interface assigned to it;","ack":"no","severity":"minor"},{"code":"F0467","dn":"topology/pod-1/node-101/local/svc-policyelem-id-0/uni/epp/fv-[uni/tn-ACIHealthCheck_jeonkim/ap-APP/epg-EPG_1]/nwissues/fault-F0467","descr":"Configuration failed for uni/tn-ACIHealthCheck_jeonkim/ap-APP/epg-EPG_1 due to DHCP Provider Not Present in Associated EPG/BD Subnet, debug message: ","ack":"no","severity":"minor"},{"code":"F0467","dn":"topology/pod-1/node-101/local/svc-policyelem-id-0/uni/epp/fv-[uni/tn-Ansible_kwakim/ap-APP/epg-EPG_1]/nwissues/fault-F0467","descr":"Configuration failed for uni/tn-Ansible_kwakim/ap-APP/epg-EPG_1 due to DHCP Provider Not Present in Associated EPG/BD Subnet, debug message: ","ack":"no","severity":"minor"},{"code":"F0467","dn":"topology/pod-1/node-101/local/svc-policyelem-id-0/uni/epp/fv-[uni/tn-Labtest_seulee/ap-APP/epg-EPG_1]/nwissues/fault-F0467","descr":"Configuration failed for uni/tn-Labtest_seulee/ap-APP/epg-EPG_1 due to DHCP Provider Not Present in Associated EPG/BD Subnet, debug message: ","ack":"no","severity":"minor"},{"code":"F0467","dn":"topology/pod-1/node-101/local/svc-policyelem-id-0/uni/epp/fv-[uni/tn-Test-Coupang_bokoo/ap-APP/epg-EPG_1]/nwissues/fault-F0467","descr":"Configuration failed for uni/tn-Test-Coupang_bokoo/ap-APP/epg-EPG_1 due to DHCP Provider Not Present in Associated EPG/BD Subnet, debug message: ","ack":"no","severity":"minor"},{"code":"F0467","dn":"topology/pod-1/node-101/local/svc-policyelem-id-0/uni/epp/fv-[uni/tn-Test_suwoo/ap-APP/epg-EPG_1]/nwissues/fault-F0467","descr":"Configuration failed for uni/tn-Test_suwoo/ap-APP/epg-EPG_1 due to DHCP Provider Not Present in Associated EPG/BD Subnet, debug message: ","ack":"no","severity":"minor"},{"code":"F0467","dn":"topology/pod-1/node-101/local/svc-policyelem-id-0/uni/epp/rtd-[uni/tn-cs-demo-shinsaegae/out-Calico/instP-SSG_NS]/nwissues/fault-F0467","descr":"Configuration failed for uni/tn-cs-demo-shinsaegae/out-Calico/instP-SSG_NS due to Prefix Entry Already Used in Another EPG, debug message: prefix-entry-already-in-use: Prefix entry sys/ctx-[vxlan-2883590]/pfx-[100.100.1.0/24] is in use;","ack":"no","severity":"minor"},{"code":"F0467","dn":"topology/pod-1/node-102/local/svc-policyelem-id-0/cdef-[uni/tn-common/brc-jeonkim_permitall]/epgCont-[uni/tn-common/ap-jeonkim_common/epg-EPG_Z]/fr-[uni/tn-common/brc-jeonkim_permitall/dirass/cons-[uni/tn-common/ap-jeonkim_common/epg-EPG_Z]-any-no]/to-[uni/tn-common/brc-jeonkim_permitall/any-[uni/tn-ACIHealthCheck_jeonkim/ctx-A/any]-type-prov_as_any/prov-[uni/tn-ACIHealthCheck_jeonkim/ctx-A/any]-any-yes]/nwissues/fault-F0467","descr":"Configuration failed for uni/tn-common/ap-jeonkim_common/epg-EPG_Z due to Invalid Contract Configuration, debug message: invalid-contract-config: Shared service provider cannot be vzAny;","ack":"no","severity":"minor"},{"code":"F0467","dn":"topology/pod-1/node-102/local/svc-policyelem-id-0/uni/epp/fv-[uni/tn-ACIHealthCheck_jeonkim/ap-APP/epg-EPG_1]/nwissues/fault-F0467","descr":"Configuration failed for uni/tn-ACIHealthCheck_jeonkim/ap-APP/epg-EPG_1 due to DHCP Provider Not Present in Associated EPG/BD Subnet, debug message: ","ack":"no","severity":"minor"},{"code":"F0467","dn":"topology/pod-1/node-102/local/svc-policyelem-id-0/uni/epp/fv-[uni/tn-Ansible_kwakim/ap-APP/epg-EPG_1]/nwissues/fault-F0467","descr":"Configuration failed for uni/tn-Ansible_kwakim/ap-APP/epg-EPG_1 due to DHCP Provider Not Present in Associated EPG/BD Subnet, debug message: ","ack":"no","severity":"minor"},{"code":"F0467","dn":"topology/pod-1/node-102/local/svc-policyelem-id-0/uni/epp/fv-[uni/tn-CISKOLAB/ap-APP/epg-SERVER-1]/node-102/stpathatt-[eth1/23]/nwissues/fault-F0467","descr":"Configuration failed for uni/tn-CISKOLAB/ap-APP/epg-SERVER-1 node 102 eth1/23 due to Invalid Path Configuration, debug message: invalid-path: Either the EpG/L3Out is not associated with a domain or the domain does not have this interface assigned to it;","ack":"no","severity":"minor"},{"code":"F0467","dn":"topology/pod-1/node-102/local/svc-policyelem-id-0/uni/epp/fv-[uni/tn-Labtest_seulee/ap-APP/epg-EPG_1]/nwissues/fault-F0467","descr":"Configuration failed for uni/tn-Labtest_seulee/ap-APP/epg-EPG_1 due to DHCP Provider Not Present in Associated EPG/BD Subnet, debug message: ","ack":"no","severity":"minor"},{"code":"F0467","dn":"topology/pod-1/node-102/local/svc-policyelem-id-0/uni/epp/fv-[uni/tn-Test-Coupang_bokoo/ap-APP/epg-EPG_1]/nwissues/fault-F0467","descr":"Configuration failed for uni/tn-Test-Coupang_bokoo/ap-APP/epg-EPG_1 due to DHCP Provider Not Present in Associated EPG/BD Subnet, debug message: ","ack":"no","severity":"minor"},{"code":"F0467","dn":"topology/pod-1/node-102/local/svc-policyelem-id-0/uni/epp/fv-[uni/tn-Test_suwoo/ap-APP/epg-EPG_1]/nwissues/fault-F0467","descr":"Configuration failed for uni/tn-Test_suwoo/ap-APP/epg-EPG_1 due to DHCP Provider Not Present in Associated EPG/BD Subnet, debug message: ","ack":"no","severity":"minor"},{"code":"F0467","dn":"topology/pod-1/node-102/local/svc-policyelem-id-0/uni/epp/rtd-[uni/tn-cs-demo-shinsaegae/out-Calico/instP-SSG_NS]/nwissues/fault-F0467","descr":"Configuration failed for uni/tn-cs-demo-shinsaegae/out-Calico/instP-SSG_NS due to Prefix Entry Already Used in Another EPG, debug message: prefix-entry-already-in-use: Prefix entry sys/ctx-[vxlan-2883590]/pfx-[100.100.1.0/24] is in use;","ack":"no","severity":"minor"}],"F0475":[{"code":"F0475","dn":"topology/pod-1/node-101/sys/tunnel-[tunnel29]/fault-F0475","descr":"Tunnel destination to ip: 12.12.12.11/32 for tunnel29 is not reachable.","ack":"no","severity":"major"},{"code":"F0475","dn":"topology/pod-1/node-102/sys/tunnel-[tunnel29]/fault-F0475","descr":"Tunnel destination to ip: 12.12.12.11/32 for tunnel29 is not reachable.","ack":"no","severity":"major"},{"code":"F0475","dn":"topology/pod-1/node-103/sys/tunnel-[tunnel24]/fault-F0475","descr":"Tunnel destination to ip: 12.12.12.11/32 for tunnel24 is not reachable.","ack":"no","severity":"major"},{"code":"F0475","dn":"topology/pod-1/node-104/sys/tunnel-[tunnel24]/fault-F0475","descr":"Tunnel destination to ip: 12.12.12.11/32 for tunnel24 is not reachable.","ack":"no","severity":"major"},{"code":"F0475","dn":"topology/pod-1/node-201/sys/tunnel-[tunnel15]/fault-F0475","descr":"Tunnel destination to ip: 12.12.12.11/32 for tunnel15 is not reachable.","ack":"no","severity":"major"},{"code":"F0475","dn":"topology/pod-1/node-201/sys/tunnel-[tunnel16]/fault-F0475","descr":"Tunnel destination to ip: 12.12.12.12/32 for tunnel16 is not reachable.","ack":"no","severity":"major"}],"F0523":[{"code":"F0523","dn":"uni/tn-CISKOLAB/ap-aci-containers-K8S_Cluster1/epg-aci-containers-default/fault-F0523","descr":"Configuration failed for EPG aci-containers-default due to BD IDs Not Allocated,Context Not present. Configure Context and/or attach Context to Bridge-group domain for application EPG or attach Context to ESG for security group.","ack":"no","severity":"minor"},{"code":"F0523","dn":"uni/tn-CISKOLAB/ap-aci-containers-K8S_Cluster1/epg-aci-containers-istio/fault-F0523","descr":"Configuration failed for EPG aci-containers-istio due to BD IDs Not Allocated,Context Not present. Configure Context and/or attach Context to Bridge-group domain for application EPG or attach Context to ESG for security group.","ack":"no","severity":"minor"},{"code":"F0523","dn":"uni/tn-CISKOLAB/ap-aci-containers-K8S_Cluster1/epg-aci-containers-nodes/fault-F0523","descr":"Configuration failed for EPG aci-containers-nodes due to BD IDs Not Allocated,Context Not present. Configure Context and/or attach Context to Bridge-group domain for application EPG or attach Context to ESG for security group.","ack":"no","severity":"minor"},{"code":"F0523","dn":"uni/tn-CISKOLAB/ap-aci-containers-K8S_Cluster1/epg-aci-containers-system/fault-F0523","descr":"Configuration failed for EPG aci-containers-system due to BD IDs Not Allocated,Context Not present. Configure Context and/or attach Context to Bridge-group domain for application EPG or attach Context to ESG for security group.","ack":"no","severity":"minor"},{"code":"F0523","dn":"uni/tn-CISKOLAB/ap-aci-containers-K8S_Cluster1/epg-redis-backend/fault-F0523","descr":"Configuration failed for EPG redis-backend due to BD IDs Not Allocated,Context Not present. Configure Context and/or attach Context to Bridge-group domain for application EPG or attach Context to ESG for security group.","ack":"no","severity":"minor"},{"code":"F0523","dn":"uni/tn-CISKOLAB/ap-aci-containers-K8S_Cluster1/epg-redis-frontend/fault-F0523","descr":"Configuration failed for EPG redis-frontend due to BD IDs Not Allocated,Context Not present. Configure Context and/or attach Context to Bridge-group domain for application EPG or attach Context to ESG for security group.","ack":"no","severity":"minor"},{"code":"F0523","dn":"uni/tn-CISKOLAB/ap-aci-containers-K8S_Cluster1/epg-redis-guestbook/fault-F0523","descr":"Configuration failed for EPG redis-guestbook due to BD IDs Not Allocated,Context Not present. Configure Context and/or attach Context to Bridge-group domain for application EPG or attach Context to ESG for security group.","ack":"no","severity":"minor"},{"code":"F0523","dn":"uni/tn-common/out-DC1-L3Out-ASA/instP-External-Net/fault-F0523","descr":"Configuration failed for EPG External-Net due to Context Not present. Configure Context and/or attach Context to Bridge-group domain for application EPG or attach Context to ESG for security group.","ack":"no","severity":"minor"},{"code":"F0523","dn":"uni/tn-common/out-DC1-L3Out-ASA/instP-K8S_Cluster1_svc_redis-guestbook_frontend/fault-F0523","descr":"Configuration failed for EPG K8S_Cluster1_svc_redis-guestbook_frontend due to Context Not present. Configure Context and/or attach Context to Bridge-group domain for application EPG or attach Context to ESG for security group.","ack":"no","severity":"minor"},{"code":"F0523","dn":"uni/tn-common/out-DC1-L3Out-ASA/instP-accordion_svc_accordion_accordion-gateway/fault-F0523","descr":"Configuration failed for EPG accordion_svc_accordion_accordion-gateway due to Context Not present. Configure Context and/or attach Context to Bridge-group domain for application EPG or attach Context to ESG for security group.","ack":"no","severity":"minor"},{"code":"F0523","dn":"uni/tn-common/out-DC1-L3Out-ASA/instP-accordion_svc_test_test/fault-F0523","descr":"Configuration failed for EPG accordion_svc_test_test due to Context Not present. Configure Context and/or attach Context to Bridge-group domain for application EPG or attach Context to ESG for security group.","ack":"no","severity":"minor"},{"code":"F0523","dn":"uni/tn-common/out-DC1-SDA-Underlay/instP-External/fault-F0523","descr":"Configuration failed for EPG External due to Context Not present. Configure Context and/or attach Context to Bridge-group domain for application EPG or attach Context to ESG for security group.","ack":"no","severity":"minor"},{"code":"F0523","dn":"uni/tn-common/out-DC1-SDA-Underlay/instP-__int_DC1-SDA-Underlay_topo/fault-F0523","descr":"Configuration failed for EPG __int_DC1-SDA-Underlay_topo due to Context Not present. Configure Context and/or attach Context to Bridge-group domain for application EPG or attach Context to ESG for security group.","ack":"no","severity":"minor"},{"code":"F0523","dn":"uni/tn-common/out-default/instP-ExtEPG/fault-F0523","descr":"Configuration failed for EPG ExtEPG due to Context Not present. Configure Context and/or attach Context to Bridge-group domain for application EPG or attach Context to ESG for security group.","ack":"no","severity":"minor"},{"code":"F0523","dn":"uni/tn-mgmt/ap-default/epg-default/fault-F0523","descr":"Configuration failed for EPG default due to BD Not present","ack":"no","severity":"minor"}],"F0532":[{"code":"F0532","dn":"topology/pod-1/node-101/sys/phys-[eth1/21]/phys/fault-F0532","descr":"Port is down, reason being notconnect(connected), used by EPG on node 101 of fabric DC1 with hostname DC1-LEAF-101","ack":"no","severity":"critical"},{"code":"F0532","dn":"topology/pod-1/node-102/sys/phys-[eth1/21]/phys/fault-F0532","descr":"Port is down, reason being notconnect(connected), used by EPG on node 102 of fabric DC1 with hostname DC1-LEAF-102","ack":"no","severity":"critical"},{"code":"F0532","dn":"topology/pod-1/node-102/sys/phys-[eth1/22]/phys/fault-F0532","descr":"Port is down, reason being notconnect(connected), used by EPG on node 102 of fabric DC1 with hostname DC1-LEAF-102","ack":"no","severity":"critical"}],"F0546":[{"code":"F0546","dn":"topology/pod-1/node-101/sys/aggr-[po1]/aggrif/fault-F0546","descr":"Port is down, reason:noOperMembers(connected), used by:Discovery","ack":"no","severity":"warning"},{"code":"F0546","dn":"topology/pod-1/node-101/sys/phys-[eth1/40]/phys/fault-F0546","descr":"Port is down, reason:sfpAbsent(connected), used by:Discovery","ack":"no","severity":"warning"},{"code":"F0546","dn":"topology/pod-1/node-102/sys/aggr-[po2]/aggrif/fault-F0546","descr":"Port is down, reason:noOperMembers(connected), used by:Discovery","ack":"no","severity":"warning"},{"code":"F0546","dn":"topology/pod-1/node-102/sys/aggr-[po4]/aggrif/fault-F0546","descr":"Port is down, reason:noOperMembers(connected), used by:Discovery","ack":"no","severity":"warning"},{"code":"F0546","dn":"topology/pod-1/node-102/sys/phys-[eth1/39]/phys/fault-F0546","descr":"Port is down, reason:sfpAbsent(connected), used by:Discovery","ack":"no","severity":"warning"},{"code":"F0546","dn":"topology/pod-1/node-102/sys/phys-[eth1/40]/phys/fault-F0546","descr":"Port is down, reason:sfpAbsent(connected), used by:Discovery","ack":"no","severity":"warning"},{"code":"F0546","dn":"topology/pod-1/node-104/sys/phys-[eth1/35]/phys/fault-F0546","descr":"Port is down, reason:mcpLoop errDisable(connected), used by:Discovery","ack":"no","severity":"warning"}],"F0565":[{"code":"F0565","dn":"uni/vmmp-VMware/dom-DSwitchTest/eppd-[uni/tn-CISKOLAB/ap-APP/epg-aaaaa]/fault-F0565","descr":"Deployment of EPG uni/tn-CISKOLAB/ap-APP/epg-aaaaa failed on domain DSwitchTest due to No valid encapsulation identifier allocated for the epg","ack":"no","severity":"major"}],"F0721":[{"code":"F0721","dn":"uni/infra/vlanns-[SDWAN-VLAN]-static/fault-F0721","descr":"VLAN/VxLAN/NVGRE pool SDWAN-VLAN deployment failed due to: Invalid or missing Encapsulation Blocks.","ack":"no","severity":"minor"}],"F0756":[{"code":"F0756","dn":"uni/infra/funcprof/accportgrp-__sn_cluster_CASE-Cluster/rsl2IfPol/fault-F0756","descr":"Could not resolve the target l2IfP-__sn_cluster_CASE-Cluster to form a named relationship. Using a default target uni/infra/l2IfP-default instead","ack":"no","severity":"minor"},{"code":"F0756","dn":"uni/tn-infra/out-mdc_l3Out/lnodep-mdc_nodeProfile/lifp-mdc_leafProfile/ospfIfP/rsIfPol/fault-F0756","descr":"Could not resolve the target ospfIfPol-mdc_ospf to form a named relationship. Using a default target uni/tn-common/ospfIfPol-default instead","ack":"no","severity":"minor"}],"F0849":[{"code":"F0849","dn":"topology/pod-1/node-102/local/svc-policyelem-id-0/uni/infra/accportprof-NH_FEX_ifselector/hports-1-1-typ-range/selectorissues/fault-F0849","descr":"Configuration failed due to port-configured-for-apic for uni/infra/accportprof-NH_FEX_ifselector/hports-1-1-typ-range for node DC1-LEAF-102","ack":"no","severity":"minor"}],"F0952":[{"code":"F0952","dn":"uni/tn-CISKOLAB/BD-aci-containers-K8S_Cluster1-node-bd/rsctx/fault-F0952","descr":"Failed to form relation to MO ctx-L3Out of class fvCtx in context ","ack":"no","severity":"warning"},{"code":"F0952","dn":"uni/tn-CISKOLAB/BD-aci-containers-K8S_Cluster1-pod-bd/rsctx/fault-F0952","descr":"Failed to form relation to MO ctx-L3Out of class fvCtx in context ","ack":"no","severity":"warning"},{"code":"F0952","dn":"uni/tn-common/BD-K8S_Cluster1_bd_kubernetes-service/rsctx/fault-F0952","descr":"Failed to form relation to MO ctx-L3Out of class fvCtx in context ","ack":"no","severity":"warning"},{"code":"F0952","dn":"uni/tn-common/BD-default/rsctx/fault-F0952","descr":"Failed to form relation to MO ctx-L3Out of class fvCtx in context ","ack":"no","severity":"warning"}],"F0955":[{"code":"F0955","dn":"uni/tn-mgmt/ap-default/epg-default/rsbd/fault-F0955","descr":"Failed to form relation to MO BD-inb-outside of class fvBD in context ","ack":"no","severity":"warning"}],"F0981":[{"code":"F0981","dn":"uni/phys-Service-Engine/rsvlanNs/fault-F0981","descr":"Failed to form relation to MO uni/infra/vlanns-[SE-Pool]-static of class fvnsVlanInstP","ack":"no","severity":"warning"}],"F0982":[{"code":"F0982","dn":"uni/infra/attentp-AEP-UCS_FI/gen-default/rsfuncToEpg-[uni/tn-OCP/ap-kubernetes/epg-kube-nodes]/fault-F0982","descr":"Failed to form relation to MO uni/tn-OCP/ap-kubernetes/epg-kube-nodes of class fvAEPg","ack":"no","severity":"warning"},{"code":"F0982","dn":"uni/infra/attentp-AEP-UCS_FI/gen-default/rsfuncToEpg-[uni/tn-SDA/ap-aci-containers-K8S_Cluster2/epg-aci-containers-nodes]/fault-F0982","descr":"Failed to form relation to MO uni/tn-SDA/ap-aci-containers-K8S_Cluster2/epg-aci-containers-nodes of class fvAEPg","ack":"no","severity":"warning"},{"code":"F0982","dn":"uni/infra/attentp-AEP-UCS_FI/gen-default/rsfuncToEpg-[uni/tn-ccp/ap-kubernetes/epg-kube-nodes]/fault-F0982","descr":"Failed to form relation to MO uni/tn-ccp/ap-kubernetes/epg-kube-nodes of class fvAEPg","ack":"no","severity":"warning"},{"code":"F0982","dn":"uni/infra/attentp-AEP-UCS_FI/gen-default/rsfuncToEpg-[uni/tn-ccp2/ap-kubernetes/epg-kube-nodes]/fault-F0982","descr":"Failed to form relation to MO uni/tn-ccp2/ap-kubernetes/epg-kube-nodes of class fvAEPg","ack":"no","severity":"warning"},{"code":"F0982","dn":"uni/infra/attentp-AEP-UCS_FI/gen-default/rsfuncToEpg-[uni/tn-ccp_cluster/ap-kubernetes/epg-kube-nodes]/fault-F0982","descr":"Failed to form relation to MO uni/tn-ccp_cluster/ap-kubernetes/epg-kube-nodes of class fvAEPg","ack":"no","severity":"warning"},{"code":"F0982","dn":"uni/infra/attentp-AEP-case/gen-default/rsfuncToEpg-[uni/tn-mgmt/ap-case/epg-case-epg]/fault-F0982","descr":"Failed to form relation to MO uni/tn-mgmt/ap-case/epg-case-epg of class fvAEPg","ack":"no","severity":"warning"}],"F0989":[{"code":"F0989","dn":"uni/infra/funcprof/accportgrp-L3Out-SDWAN/rsattEntP/fault-F0989","descr":"Failed to form relation to MO uni/infra/attentp-AEP-SDWAN of class infraAttEntityP","ack":"no","severity":"warning"},{"code":"F0989","dn":"uni/infra/funcprof/accportgrp-__sn_cluster_CASE-Cluster/rsattEntP/fault-F0989","descr":"Failed to form relation to MO uni/infra/attentp-__sn_cluster_CASE-Cluster of class infraAttEntityP","ack":"no","severity":"warning"}],"F1011":[{"code":"F1011","dn":"uni/infra/accportprof-DC1-LEAF-103/hports-Eth25-typ-range/rsaccBaseGrp/fault-F1011","descr":"Failed to form relation to MO uni/infra/funcprof/accbundle-vPC-103_104-1_25 of class infraAccBndlGrp","ack":"no","severity":"warning"},{"code":"F1011","dn":"uni/infra/accportprof-DC1-LEAF-104/hports-Eth25-typ-range/rsaccBaseGrp/fault-F1011","descr":"Failed to form relation to MO uni/infra/funcprof/accbundle-vPC-103_104-1_25 of class infraAccBndlGrp","ack":"no","severity":"warning"}],"F1020":[{"code":"F1020","dn":"uni/tn-common/out-DC1-L3Out-ASA/rsectx/fault-F1020","descr":"Failed to form relation to MO ctx-L3Out of class fvCtx in context ","ack":"no","severity":"warning"},{"code":"F1020","dn":"uni/tn-common/out-DC1-SDA-Underlay/rsectx/fault-F1020","descr":"Failed to form relation to MO ctx-L3Out of class fvCtx in context ","ack":"no","severity":"warning"},{"code":"F1020","dn":"uni/tn-common/out-default/rsectx/fault-F1020","descr":"Failed to form relation to MO ctx-EP-VRF of class fvCtx in context ","ack":"no","severity":"warning"}],"F1056":[{"code":"F1056","dn":"uni/fabric/monfab-default/slsrc-Syslog-to-Prime/rsdestGroup/fault-F1056","descr":"Failed to form relation to MO uni/fabric/slgroup-Syslog-Server of class syslogGroup","ack":"no","severity":"warning"}],"F1123":[{"code":"F1123","dn":"uni/tn-common/cif-Leaking_Between_Tenant/rsif/fault-F1123","descr":"Failed to form relation to MO uni/tn-0615_Lab/brc-L3_out_Permit of class vzBrCP","ack":"no","severity":"warning"}],"F1186":[{"code":"F1186","dn":"topology/pod-1/node-101/sys/phys-[eth1/21]/fault-F1186","descr":"Port configuration failure.                                   Reason: 2                                   Failed Config: l1:PhysIfspeed_failed_flag","ack":"no","severity":"warning"},{"code":"F1186","dn":"topology/pod-1/node-102/sys/phys-[eth1/21]/fault-F1186","descr":"Port configuration failure.                                   Reason: 2                                   Failed Config: l1:PhysIfspeed_failed_flag","ack":"no","severity":"warning"},{"code":"F1186","dn":"topology/pod-1/node-102/sys/phys-[eth1/22]/fault-F1186","descr":"Port configuration failure.                                   Reason: 2                                   Failed Config: l1:PhysIfspeed_failed_flag","ack":"no","severity":"warning"}],"F1296":[{"code":"F1296","dn":"topology/pod-1/node-101/sys/vpc/inst/dom-10/if-2/fault-F1296","descr":"vPC VPC-101_102_1_25 is down in Pod 1 node 101 fabric hostname DC1-LEAF-101","ack":"no","severity":"major"},{"code":"F1296","dn":"topology/pod-1/node-102/sys/vpc/inst/dom-10/if-2/fault-F1296","descr":"vPC VPC-101_102_1_25 is down in Pod 1 node 102 fabric hostname DC1-LEAF-102","ack":"no","severity":"major"}],"F1360":[{"code":"F1360","dn":"topology/pod-1/node-101/sys/coop/inst/dom-overlay-1/oracle-[10.0.136.64/32]/fault-F1360","descr":"Operational state is down, reason:Route not reachable","ack":"no","severity":"warning"},{"code":"F1360","dn":"topology/pod-1/node-102/sys/coop/inst/dom-overlay-1/oracle-[10.0.136.64/32]/fault-F1360","descr":"Operational state is down, reason:Route not reachable","ack":"no","severity":"warning"},{"code":"F1360","dn":"topology/pod-1/node-103/sys/coop/inst/dom-overlay-1/oracle-[10.0.136.64/32]/fault-F1360","descr":"Operational state is down, reason:Route not reachable","ack":"no","severity":"warning"},{"code":"F1360","dn":"topology/pod-1/node-104/sys/coop/inst/dom-overlay-1/oracle-[10.0.136.64/32]/fault-F1360","descr":"Operational state is down, reason:Route not reachable","ack":"no","severity":"warning"},{"code":"F1360","dn":"topology/pod-1/node-201/sys/coop/inst/dom-overlay-1/oracle-[10.0.136.64/32]/fault-F1360","descr":"Operational state is down, reason:Route not reachable","ack":"no","severity":"warning"}],"F1394":[{"code":"F1394","dn":"topology/pod-1/node-101/sys/phys-[eth1/52]/phys/fault-F1394","descr":"Port is down, reason:sfpAbsent(connected), used by:Fabric","ack":"no","severity":"minor"},{"code":"F1394","dn":"topology/pod-1/node-101/sys/phys-[eth1/54]/phys/fault-F1394","descr":"Port is down, reason:notconnect(connected), used by:Fabric","ack":"no","severity":"minor"},{"code":"F1394","dn":"topology/pod-1/node-102/sys/phys-[eth1/52]/phys/fault-F1394","descr":"Port is down, reason:sfpAbsent(connected), used by:Fabric","ack":"no","severity":"minor"},{"code":"F1394","dn":"topology/pod-1/node-102/sys/phys-[eth1/54]/phys/fault-F1394","descr":"Port is down, reason:notconnect(connected), used by:Fabric","ack":"no","severity":"minor"},{"code":"F1394","dn":"topology/pod-1/node-104/sys/phys-[eth1/54]/phys/fault-F1394","descr":"Port is down, reason:notconnect(connected), used by:Fabric","ack":"no","severity":"minor"},{"code":"F1394","dn":"topology/pod-1/node-201/sys/phys-[eth1/21]/phys/fault-F1394","descr":"Port is down, reason:sfpAbsent(connected), used by:Fabric","ack":"no","severity":"minor"}],"F1451":[{"code":"F1451","dn":"topology/pod-1/node-101/sys/ch/psuslot-1/psu/fault-F1451","descr":"Power supply shutdown. (serial number LIT20443ERU)","ack":"no","severity":"minor"},{"code":"F1451","dn":"topology/pod-1/node-102/sys/ch/psuslot-1/psu/fault-F1451","descr":"Power supply shutdown. (serial number LIT21202TX7)","ack":"no","severity":"minor"},{"code":"F1451","dn":"topology/pod-1/node-104/sys/ch/psuslot-2/psu/fault-F1451","descr":"Power supply shutdown. (serial number )","ack":"no","severity":"minor"}],"F1543":[{"code":"F1543","dn":"topology/pod-1/node-202/fault-F1543","descr":"Node 202 with hostname DC1-SPINE-202 is inactive and not reachable.","ack":"no","severity":"critical"}],"F1606":[{"code":"F1606","dn":"comp/prov-VMware/ctrlr-[DC1-CLUSTER01-DVS]-DC1-vCenter/sw-dvs-11/extpol-dvportgroup-1370/fault-F1606","descr":"Operational issues detected on portgroup: N9K_Test_VPC (L1-L2) in VM Controller:DC1-vCenter, VM Domain:DC1-CLUSTER01-DVS, VM Provider:VMware, error: Cannot find an EPG policy in the domain for the portgroup.","ack":"no","severity":"minor"},{"code":"F1606","dn":"comp/prov-VMware/ctrlr-[DC1-CLUSTER01-DVS]-DC1-vCenter/sw-dvs-11/extpol-dvportgroup-1371/fault-F1606","descr":"Operational issues detected on portgroup: N9K_Test_Leaf_1 (1.X) in VM Controller:DC1-vCenter, VM Domain:DC1-CLUSTER01-DVS, VM Provider:VMware, error: Cannot find an EPG policy in the domain for the portgroup.","ack":"no","severity":"minor"},{"code":"F1606","dn":"comp/prov-VMware/ctrlr-[DC1-CLUSTER01-DVS]-DC1-vCenter/sw-dvs-11/extpol-dvportgroup-1372/fault-F1606","descr":"Operational issues detected on portgroup: N9K_Test_Leaf_2 (2.X) in VM Controller:DC1-vCenter, VM Domain:DC1-CLUSTER01-DVS, VM Provider:VMware, error: Cannot find an EPG policy in the domain for the portgroup.","ack":"no","severity":"minor"},{"code":"F1606","dn":"comp/prov-VMware/ctrlr-[DC1-CLUSTER01-DVS]-DC1-vCenter/sw-dvs-11/extpol-dvportgroup-1386/fault-F1606","descr":"Operational issues detected on portgroup: N9K_Test_DPG in VM Controller:DC1-vCenter, VM Domain:DC1-CLUSTER01-DVS, VM Provider:VMware, error: Cannot find an EPG policy in the domain for the portgroup.","ack":"no","severity":"minor"},{"code":"F1606","dn":"comp/prov-VMware/ctrlr-[DC1-CLUSTER02-DVS]-DC1-vCenter/sw-dvs-10/extpol-dvportgroup-1670/fault-F1606","descr":"Operational issues detected on portgroup: Shinwoo_Labs in VM Controller:DC1-vCenter, VM Domain:DC1-CLUSTER02-DVS, VM Provider:VMware, error: Cannot find an EPG policy in the domain for the portgroup.","ack":"no","severity":"minor"},{"code":"F1606","dn":"comp/prov-VMware/ctrlr-[DC1-CLUSTER03-DVS]-DC1-vCenter/sw-dvs-31/extpol-dvportgroup-2156/fault-F1606","descr":"Operational issues detected on portgroup: cs-demo-K8S|1109 in VM Controller:DC1-vCenter, VM Domain:DC1-CLUSTER03-DVS, VM Provider:VMware, error: Cannot find an EPG policy in the domain for the portgroup.","ack":"no","severity":"minor"},{"code":"F1606","dn":"comp/prov-VMware/ctrlr-[DC1-CLUSTER03-DVS]-DC1-vCenter/sw-dvs-31/extpol-dvportgroup-2571/fault-F1606","descr":"Operational issues detected on portgroup: insekim_dev in VM Controller:DC1-vCenter, VM Domain:DC1-CLUSTER03-DVS, VM Provider:VMware, error: Cannot find an EPG policy in the domain for the portgroup.","ack":"no","severity":"minor"},{"code":"F1606","dn":"comp/prov-VMware/ctrlr-[DSwitchTest]-vc/sw-dvs-2524/extpol-dvportgroup-2528/fault-F1606","descr":"Operational issues detected on portgroup: DPortGroup 1 in VM Controller:vc, VM Domain:DSwitchTest, VM Provider:VMware, error: Cannot find an EPG policy in the domain for the portgroup.","ack":"no","severity":"minor"}],"F1651":[{"code":"F1651","dn":"expcont/expstatus-tsexp-default/fault-F1651","descr":"Upload triggered at 2022-03-30T13:06:54.881+09:00 for policy tsexp-default failed . Check operational status for details.","ack":"no","severity":"minor"},{"code":"F1651","dn":"expcont/expstatus-tsod-6487250992837685192.168.6.11/fault-F1651","descr":"Upload triggered at 2021-06-24T17:43:50.206+09:00 for policy tsod-6487250992837685192.168.6.11 failed . Check operational status for details.","ack":"no","severity":"minor"},{"code":"F1651","dn":"expcont/expstatus-tsod-6487250992837685192.168.6.12/fault-F1651","descr":"Upload triggered at 2021-06-24T17:44:01.758+09:00 for policy tsod-6487250992837685192.168.6.12 timedOut . Check operational status for details.","ack":"no","severity":"minor"},{"code":"F1651","dn":"expcont/expstatus-tsod-9876666477638180192.168.6.11/fault-F1651","descr":"Upload triggered at 2021-04-20T23:06:01.932+09:00 for policy tsod-9876666477638180192.168.6.11 failed . Check operational status for details.","ack":"no","severity":"minor"},{"code":"F1651","dn":"expcont/expstatus-tsod-9876666477638180192.168.6.12/fault-F1651","descr":"Upload triggered at 2021-04-20T23:05:50.996+09:00 for policy tsod-9876666477638180192.168.6.12 failed . Check operational status for details.","ack":"no","severity":"minor"}],"F1888":[{"code":"F1888","dn":"topology/pod-1/node-101/sys/stp/inst/if-[eth1/42]/fault-F1888","descr":"Native vlan is not configured on interface eth1/42 on node 101 of fabric DC1 with a hostname DC1-LEAF-101, but it is receiving MST(802.1s) BPDUs. This could result in a layer2 topology with a loop","ack":"no","severity":"critical"}],"F2330":[{"code":"F2330","dn":"uni/tn-cs-demo-k8s/out-l3out_k8s/pimextp/fault-F2330","descr":"Configuration is invalid due to PIM is not supported on floating SVIs","ack":"no","severity":"minor"}],"F2409":[{"code":"F2409","dn":"uni/tn-common/BD-K8S_Cluster1_bd_kubernetes-service/fault-F2409","descr":"Configuration is invalid due to l3-mcast-is-enabled-on-vrf-where-bd-has-ip-learn-disable.","ack":"no","severity":"warning"}],"F2740":[{"code":"F2740","dn":"topology/pod-1/node-101/sys/phys-[eth1/21]/phys/fault/fault-F2740","descr":"Port speed configured on node-101 DC1-LEAF-101 interface eth1/21 is invalid or unsupported","ack":"no","severity":"warning"},{"code":"F2740","dn":"topology/pod-1/node-102/sys/phys-[eth1/21]/phys/fault/fault-F2740","descr":"Port speed configured on node-102 DC1-LEAF-102 interface eth1/21 is invalid or unsupported","ack":"no","severity":"warning"},{"code":"F2740","dn":"topology/pod-1/node-102/sys/phys-[eth1/22]/phys/fault/fault-F2740","descr":"Port speed configured on node-102 DC1-LEAF-102 interface eth1/22 is invalid or unsupported","ack":"no","severity":"warning"}],"F2840":[{"code":"F2840","dn":"comp/prov-VMware/ctrlr-[DC1-CLUSTER01-DVS]-DC1-vCenter/hv-host-1165/fault-F2840","descr":"Operational issues detected for Host 10.70.136.75 in VMM controller: 10.70.136.15 with name DC1-vCenter in datacenter  DC1 in domain: DC1-CLUSTER01-DVS due to error: ESX Host is disconnected or not responding.","ack":"no","severity":"major"},{"code":"F2840","dn":"comp/prov-VMware/ctrlr-[DC1-CLUSTER02-DVS]-DC1-vCenter/hv-host-1165/fault-F2840","descr":"Operational issues detected for Host 10.70.136.75 in VMM controller: 10.70.136.15 with name DC1-vCenter in datacenter  DC1 in domain: DC1-CLUSTER02-DVS due to error: ESX Host is disconnected or not responding.","ack":"no","severity":"major"},{"code":"F2840","dn":"comp/prov-VMware/ctrlr-[DC1-CLUSTER03-DVS]-DC1-vCenter/hv-host-1165/fault-F2840","descr":"Operational issues detected for Host 10.70.136.75 in VMM controller: 10.70.136.15 with name DC1-vCenter in datacenter  DC1 in domain: DC1-CLUSTER03-DVS due to error: ESX Host is disconnected or not responding.","ack":"no","severity":"major"},{"code":"F2840","dn":"comp/prov-VMware/ctrlr-[DC1-CLUSTER05-DVS]-DC1-vCenter/hv-host-1165/fault-F2840","descr":"Operational issues detected for Host 10.70.136.75 in VMM controller: 10.70.136.15 with name DC1-vCenter in datacenter  DC1 in domain: DC1-CLUSTER05-DVS due to error: ESX Host is disconnected or not responding.","ack":"no","severity":"major"},{"code":"F2840","dn":"comp/prov-VMware/ctrlr-[DSwitchTest]-vc/hv-host-1165/fault-F2840","descr":"Operational issues detected for Host 10.70.136.75 in VMM controller: 10.70.136.15 with name vc in datacenter  DC1 in domain: DSwitchTest due to error: ESX Host is disconnected or not responding.","ack":"no","severity":"major"}],"F3254":[{"code":"F3254","dn":"pluginContr/plugin-Cisco_NIBASE/fault-F3254","descr":"Application Nexus Insights Cloud Connector is not healthy. Info: Problems in Cisco_NIBASE-ClusterService: Sub-group baseacicc has 1 container(s) in starting state. Sub-group baseacifsvagent has 1 container(s) in starting state. Sub-group baseaciftriage has 1 container(s) in starting state. ","ack":"no","severity":"minor"}],"F3634":[{"code":"F3634","dn":"uni/tn-cs-demo-k8s/out-l3out_k8s/lnodep-nodeProfile1/protp/rsBestPathCtrlPol/fault-F3634","descr":"Failed to form relation to MO bestpath-Enabled of class bgpBestPathCtrlPol in context ","ack":"no","severity":"warning"}],"F3848":[{"code":"F3848","dn":"topology/pod-1/node-1/sys/ch/psuslot-5/psu/fault-F3848","descr":"Power supply unit on Node 1 with hostname apic1 is shutdown","ack":"no","severity":"minor"},{"code":"F3848","dn":"topology/pod-1/node-2/sys/ch/psuslot-5/psu/fault-F3848","descr":"Power supply unit on Node 2 with hostname apic2 is shutdown","ack":"no","severity":"minor"},{"code":"F3848","dn":"topology/pod-1/node-3/sys/ch/psuslot-5/psu/fault-F3848","descr":"Power supply unit on Node 3 with hostname apic3 is shutdown","ack":"no","severity":"minor"}],"F93337":[{"code":"F93337","dn":"comp/prov-VMware/ctrlr-[DC1-CLUSTER01-DVS]-DC1-vCenter/hv-host-1006/fault-F93337","descr":"TCA: memory usage current value(compHostStats15min:memUsageLast) value 86% raised above threshold 80%","ack":"no","severity":"warning"},{"code":"F93337","dn":"comp/prov-VMware/ctrlr-[DC1-CLUSTER01-DVS]-DC1-vCenter/hv-host-1009/fault-F93337","descr":"TCA: memory usage current value(compHostStats15min:memUsageLast) value 85% raised above threshold 80%","ack":"no","severity":"warning"},{"code":"F93337","dn":"comp/prov-VMware/ctrlr-[DC1-CLUSTER01-DVS]-DC1-vCenter/hv-host-1012/fault-F93337","descr":"TCA: memory usage current value(compHostStats15min:memUsageLast) value 85% raised above threshold 80%","ack":"no","severity":"warning"},{"code":"F93337","dn":"comp/prov-VMware/ctrlr-[DC1-CLUSTER01-DVS]-DC1-vCenter/hv-host-1114/fault-F93337","descr":"TCA: memory usage current value(compHostStats15min:memUsageLast) value 88% raised above threshold 80%","ack":"no","severity":"warning"},{"code":"F93337","dn":"comp/prov-VMware/ctrlr-[DC1-CLUSTER01-DVS]-DC1-vCenter/hv-host-1117/fault-F93337","descr":"TCA: memory usage current value(compHostStats15min:memUsageLast) value 81% raised above threshold 80%","ack":"no","severity":"warning"},{"code":"F93337","dn":"comp/prov-VMware/ctrlr-[DC1-CLUSTER01-DVS]-DC1-vCenter/hv-host-1120/fault-F93337","descr":"TCA: memory usage current value(compHostStats15min:memUsageLast) value 97% raised above threshold 95%","ack":"no","severity":"major"},{"code":"F93337","dn":"comp/prov-VMware/ctrlr-[DC1-CLUSTER01-DVS]-DC1-vCenter/hv-host-1123/fault-F93337","descr":"TCA: memory usage current value(compHostStats15min:memUsageLast) value 84% raised above threshold 80%","ack":"no","severity":"warning"},{"code":"F93337","dn":"comp/prov-VMware/ctrlr-[DC1-CLUSTER02-DVS]-DC1-vCenter/hv-host-1006/fault-F93337","descr":"TCA: memory usage current value(compHostStats15min:memUsageLast) value 87% raised above threshold 80%","ack":"no","severity":"warning"},{"code":"F93337","dn":"comp/prov-VMware/ctrlr-[DC1-CLUSTER02-DVS]-DC1-vCenter/hv-host-1009/fault-F93337","descr":"TCA: memory usage current value(compHostStats15min:memUsageLast) value 85% raised above threshold 80%","ack":"no","severity":"warning"},{"code":"F93337","dn":"comp/prov-VMware/ctrlr-[DC1-CLUSTER02-DVS]-DC1-vCenter/hv-host-1012/fault-F93337","descr":"TCA: memory usage current value(compHostStats15min:memUsageLast) value 82% raised above threshold 80%","ack":"no","severity":"warning"},{"code":"F93337","dn":"comp/prov-VMware/ctrlr-[DC1-CLUSTER02-DVS]-DC1-vCenter/hv-host-1114/fault-F93337","descr":"TCA: memory usage current value(compHostStats15min:memUsageLast) value 88% raised above threshold 80%","ack":"no","severity":"warning"},{"code":"F93337","dn":"comp/prov-VMware/ctrlr-[DC1-CLUSTER02-DVS]-DC1-vCenter/hv-host-1117/fault-F93337","descr":"TCA: memory usage current value(compHostStats15min:memUsageLast) value 81% raised above threshold 80%","ack":"no","severity":"warning"},{"code":"F93337","dn":"comp/prov-VMware/ctrlr-[DC1-CLUSTER02-DVS]-DC1-vCenter/hv-host-1120/fault-F93337","descr":"TCA: memory usage current value(compHostStats15min:memUsageLast) value 98% raised above threshold 95%","ack":"no","severity":"major"},{"code":"F93337","dn":"comp/prov-VMware/ctrlr-[DC1-CLUSTER02-DVS]-DC1-vCenter/hv-host-1123/fault-F93337","descr":"TCA: memory usage current value(compHostStats15min:memUsageLast) value 84% raised above threshold 80%","ack":"no","severity":"warning"},{"code":"F93337","dn":"comp/prov-VMware/ctrlr-[DC1-CLUSTER03-DVS]-DC1-vCenter/hv-host-1006/fault-F93337","descr":"TCA: memory usage current value(compHostStats15min:memUsageLast) value 86% raised above threshold 80%","ack":"no","severity":"warning"},{"code":"F93337","dn":"comp/prov-VMware/ctrlr-[DC1-CLUSTER03-DVS]-DC1-vCenter/hv-host-1009/fault-F93337","descr":"TCA: memory usage current value(compHostStats15min:memUsageLast) value 85% raised above threshold 80%","ack":"no","severity":"warning"},{"code":"F93337","dn":"comp/prov-VMware/ctrlr-[DC1-CLUSTER03-DVS]-DC1-vCenter/hv-host-1012/fault-F93337","descr":"TCA: memory usage current value(compHostStats15min:memUsageLast) value 85% raised above threshold 80%","ack":"no","severity":"warning"},{"code":"F93337","dn":"comp/prov-VMware/ctrlr-[DC1-CLUSTER03-DVS]-DC1-vCenter/hv-host-1114/fault-F93337","descr":"TCA: memory usage current value(compHostStats15min:memUsageLast) value 88% raised above threshold 80%","ack":"no","severity":"warning"},{"code":"F93337","dn":"comp/prov-VMware/ctrlr-[DC1-CLUSTER03-DVS]-DC1-vCenter/hv-host-1117/fault-F93337","descr":"TCA: memory usage current value(compHostStats15min:memUsageLast) value 81% raised above threshold 80%","ack":"no","severity":"warning"},{"code":"F93337","dn":"comp/prov-VMware/ctrlr-[DC1-CLUSTER03-DVS]-DC1-vCenter/hv-host-1120/fault-F93337","descr":"TCA: memory usage current value(compHostStats15min:memUsageLast) value 98% raised above threshold 95%","ack":"no","severity":"major"},{"code":"F93337","dn":"comp/prov-VMware/ctrlr-[DC1-CLUSTER03-DVS]-DC1-vCenter/hv-host-1123/fault-F93337","descr":"TCA: memory usage current value(compHostStats15min:memUsageLast) value 84% raised above threshold 80%","ack":"no","severity":"warning"},{"code":"F93337","dn":"comp/prov-VMware/ctrlr-[DC1-CLUSTER05-DVS]-DC1-vCenter/hv-host-1006/fault-F93337","descr":"TCA: memory usage current value(compHostStats15min:memUsageLast) value 86% raised above threshold 80%","ack":"no","severity":"warning"},{"code":"F93337","dn":"comp/prov-VMware/ctrlr-[DC1-CLUSTER05-DVS]-DC1-vCenter/hv-host-1009/fault-F93337","descr":"TCA: memory usage current value(compHostStats15min:memUsageLast) value 85% raised above threshold 80%","ack":"no","severity":"warning"},{"code":"F93337","dn":"comp/prov-VMware/ctrlr-[DC1-CLUSTER05-DVS]-DC1-vCenter/hv-host-1012/fault-F93337","descr":"TCA: memory usage current value(compHostStats15min:memUsageLast) value 85% raised above threshold 80%","ack":"no","severity":"warning"},{"code":"F93337","dn":"comp/prov-VMware/ctrlr-[DC1-CLUSTER05-DVS]-DC1-vCenter/hv-host-1114/fault-F93337","descr":"TCA: memory usage current value(compHostStats15min:memUsageLast) value 88% raised above threshold 80%","ack":"no","severity":"warning"},{"code":"F93337","dn":"comp/prov-VMware/ctrlr-[DC1-CLUSTER05-DVS]-DC1-vCenter/hv-host-1117/fault-F93337","descr":"TCA: memory usage current value(compHostStats15min:memUsageLast) value 81% raised above threshold 80%","ack":"no","severity":"warning"},{"code":"F93337","dn":"comp/prov-VMware/ctrlr-[DC1-CLUSTER05-DVS]-DC1-vCenter/hv-host-1120/fault-F93337","descr":"TCA: memory usage current value(compHostStats15min:memUsageLast) value 97% raised above threshold 95%","ack":"no","severity":"major"},{"code":"F93337","dn":"comp/prov-VMware/ctrlr-[DC1-CLUSTER05-DVS]-DC1-vCenter/hv-host-1123/fault-F93337","descr":"TCA: memory usage current value(compHostStats15min:memUsageLast) value 84% raised above threshold 80%","ack":"no","severity":"warning"}]},"faultRecommendations":{"F0103":{"explanation":"This fault occurs when a physical interface on a controller is in the link-down state.","recommendation":"If you see this fault, take the following actions:","steps":["Verify that the physical port is properly connected to the peer device.","If the above action did not resolve the issue, create a tech-support file and contact Cisco TAC."]},"F0132":{"explanation":"This fault is raised when Remote or External disruptive operations on VMM Controller are detected.","recommendation":"If you see this fault, take the following actions:","steps":["Ensure all vCenter hosts are in connected state and online","Ensure at least one VM exists within the vCenter Inventory","Ensure there are no VMs in an 'Unreachable' state","Manually retrigger a VMM inventory sync by going to the VM networking -\u003e Inventory -\u003e Expand 'VMware' -\u003e Expand Domain -\u003e Expand 'Controllers' -\u003e Right click on the controller and select \"Trigger Inventory Sync\"","If the above actions did not resolve the issue, collect tech-support file and contact Cisco TAC."]},"F0299":{"explanation":"This fault occurs when the peer state is not established","recommendation":"To recover from this fault, try the following actions","steps":["Look at any configuration issues","Verify the configuration is correct/complete","Check network connectivity to the peer","If the above actions did not resolve the issue, generate the show tech-support file and contact Cisco TAC."]},"F0413":{"explanation":"This fault occurs when the the psu is missing","recommendation":"To recover from this fault, try the following actions","steps":["Connect power supply unit","If the above actions did not resolve the issue, create a show tech-support file and contact Cisco TAC"]},"F0467":{"explanation":"This fault occurs when an End Point Group / End Point Security Group is incompletely or incorrectly configured.","recommendation":"If you see this fault, take the following actions:","steps":["Look at the configuration for issues","For bd-not-present, this could be a temporary issue when the bridge domain has not yet been deployed to the node. If the EPG is associated with the default bridge domain, check the Connectivity Instrumentation Policy","For context-not-present, this could be a temporary issue while the VRF has not yet been deployed to the node. If the EPG is associated with the default VRF, check the Connectivity Instrumentation Policy under Networking / Protocol Policies in common tenant","For vlan-capacity, check that the number of configured EPGs and bridge domains deployed on a node do not exceed the supported number","For vxlan-capacity, check that the number of configured EPGs, bridge domains and VRFs deployed on a node do not exceed the supported number","For invalid-path, check that the configured path exists and is valid. Following issues are possible: The path (i.e. port/port-channel/Attachable-Profile/Loose-Node) getting referred does not exist on the node. The domain associated with the EPG is not allowed to use the specified path. Check the Attachable Profile configuration associated with the domain. The path (i.e. port/port-channel/Attachable-Profile/Loose-Node) is deployed on FEX and is part of l2Out/l3Out. l2Out and l3Out are NOT supported on FEX. L3Dom associated with the L3out does not exist. Configure a valid L3 Domain and associate it with the L3Out","For port-part-of-port-channel, the configured interface is already configured as a port channel member","For port-configured-as-l3, the configured interface is already configured as L3","For port-configured-as-l2, the configured interface is referring to an interface that is already configured as L2","For port-configured-for-fex, the configured interface is already configured for attaching to a FEX","For port-configured-for-apic, the configured interface is connected to a controller","For port-channel-capacity, check that the number of configured port channels deployed on a node do not exceed the supported number","For native-or-untagged-encap-failure, multiple encaps are configured as native or untagged on the same path. Check the configured mode type","For multiple-external-encap, a bridge domain can be extended outside the fabric using only one external encap per node","For multiple-ctx-configuration, an L3 interface can belong to only 1 VRF at a time","For encap-already-in-use, another EPG is already configured using this encap","For invalid-vlan :","This EPG's encap may not be valid for the domain on which the EPG is configured","Check Fabric -\u003e Acccess Policies -\u003e Switches -\u003e Leaf Switches -\u003e Profile -\u003e has a leaf profile defined with required node where config is deployed.","Check leaf-profile is associated with interface selector with target profile.","Check whether Fabric -\u003e Access Policies -\u003e Interface -\u003e Leaf Interfaces -\u003e Profiles has interface profile configured with required port and associated to leaf interface policy group.","Check configured leaf interface policy-group in Fabric -\u003e Access Policies -\u003e Interface -\u003e Leaf Interfaces -\u003e Policy Groups has ?Attached Entity Profile? configured.","Attached Entity profile should have domain configured with vlan-pool contains deployed vlan.","For insufficient vlan, check the sum of number of EPG and number of BD applied on switch which should not exceed the capapcity of ToR. Check scalability guide.","For path-wiring-issues, the configured interface has wiring issues","For router-id-conflict ensure that same router ID is used for node in the VRF. Also ensure that node specified under \"Logical interface profile\" has been added to \"Logical node profile\".","For port configured as q-in-q tunnel originator/terminator, Configure Leaf Interface Profile with policy-group enabled with âL2 Interface policyâ with edgeport turned-on. And also make sure to create Switch Association with Associated Interface Selector Profiles","For further details, refer to the documentation for fv:NwIssues","Verify the End Point Group configuration is correct and complete","If the above action did not resolve the issue, create a tech-support file and contact Cisco TAC."]},"F0475":{"explanation":"This fault occurs when destination becomes unreachable.","recommendation":"To correct this fault, please ensure that the destination is reachable.","steps":[]},"F0523":{"explanation":"This fault occurs when an End Point Group / End Point Security Group is incompletely or incorrectly configured.","recommendation":"If you see this fault, take the following actions:","steps":["Look at the configuration for issues","Verify the End Point Group configuration is correct and complete","If the above action did not resolve the issue, create a tech-support file and contact Cisco TAC."]},"F0532":{"explanation":"This fault occurs when a port is down and is in use for epg","recommendation":"If you see this fault, take the following actions","steps":["Check the port connectivity","Remove the configuration or administratively shut the port if the port is not in use","To remove the static port configuration from EPG go to Tenant-\u003eApplicationProfile-\u003eApplicationEPG-\u003eStatic Ports and remove the affected port if not being used.","For mcp-loop-err-disable, this could be due to a loop in the network. Check the config to resolve any loops","For lacp suspended ports, check for following issues -","Check whether peer device supports lacp or not.","Enable LACP feature in peer device, if peer device requires explicit global configuration.","Check vlan range configured part of member interface and port-channel configurations matches.","Check whether peer physical interface is added to port-channel as member interface.","Check whether lacp is configured on member interface of peer device.","If peer switch is of Cisco's, issue \"show lacp counters\" and verify interfaces of peer device are sending LACP PDU.","Using the \"show etherchannel summary\"/\"show port-channel summary\" command, ensure that the port-channel shows the S (Layer-2) and U (in use) flags, and that both the interfaces appear in the ports column with the P (bundled) flag.","If peer switch or router is not manufactured by Cisco, Please contact customer support of peer device's manufacturer for not sending lacp or recommended configuration guidelines.","For reason of suspend(connected) port, check whether VPC domain is configured in GUI Fabric-\u003e External Access/Access Policies -\u003eVirtual Port Channel defaul to tie two switches part of VPC domain if intent is to make two switches part of VPC.","If the above actions did not resolve the issue, create a tech-support file and contact Cisco TAC."]},"F0546":{"explanation":"This fault occurs when a port goes down","recommendation":"If you see this fault, take the following actions","steps":["Check the port connectivity","Administratively shut the port if the port is not in use","For mcp-loop-err-disable, this could be due to a loop in the network. Check the config to resolve any loops","If the above action did not resolve the issue, create a tech-support file and contact Cisco TAC."]},"F0565":{"explanation":"This fault is raised when the Endpoint Group cannot be deployed due to a missing or invalid configuration.","recommendation":"If you see this fault, take the following actions:","steps":["Verify that a VLAN pool is associated to the VMM Domain.","If a Port Encap value is specified in the Endpoint Group-to-VMM association, verify that this value is a VLAN encap and it is part of an encapsulation block with static allocation mode in the VLAN pool. VXLAN Port Encap is not supported.","Disable EPG isolation if the EPG is associated with a VMware Domain in AVS mode, or a Microsoft(SCVMM) Domain.","Review the fault message and add missing or remove invalid configuration.","Check whether required encap blocks are configured in pool.","If the above actions did not resolve the issue, collect tech-support file and contact Cisco TAC."]},"F0721":{"explanation":"This fault is raised when a VLAN/VxLAN/NVGRE pool cannot be deployed due to a missing or invalid configuration.","recommendation":"If you see this fault, take the following actions:","steps":["Review the fault message and correct the invalid configuration.","If the above actions did not resolve the issue, collect a tech-support file and contact Cisco TAC."]},"F0756":{"explanation":"This fault occurs when a configured target of a named relationship cannot be resolved.","recommendation":"If you see this fault, take the following actions:","steps":["Verify that the configuration for the named target is correct and complete, and that it exists","Verify the configuration for the specific relationship is correct and complete.","If the above actions did not resolve the issue, create a tech-support file and contact Cisco TAC."]},"F0849":{"explanation":"This fault occurs when a infra selector (port selector, card selector, node selector etc.) is incorrectly configured.","recommendation":"If you see this fault, take the following actions:","steps":["Look at the configuration for issues","For invalid-port, check the infra port selector, it should have only leaf host ports or fex host ports. Fabric ports are not allowed to be configured using infra port selector.","For port-configured-for-apic, check the infra port selector and the associated policies. Port connected to the controller can be configured for limited policies. Its allowed to be associated with only infra::AccPortGrp.","For invalid-card, check the infra card selector, its referring to a card which does not exist. Fault will clear once the card is added to the node.","For further details, refer to the documentation for fabric:SelectorIssues","Verify the infra selector configuration is correct and complete","If the above action did not resolve the issue, create a tech-support file and contact Cisco TAC."]},"F0952":{"explanation":"The object refers to an object that was not found.","recommendation":"Make sure that referenced object exists and the name is spelled correctly in the relation object.","steps":[]},"F0955":{"explanation":"The object refers to an object that was not found.","recommendation":"Make sure that referenced object exists and the name is spelled correctly in the relation object.","steps":[]},"F0981":{"explanation":"The object refers to an object that was not found.","recommendation":"Make sure that referenced object exists and the name is spelled correctly in the relation object.","steps":[]},"F0982":{"explanation":"The object refers to an object that was not found.","recommendation":"Make sure that referenced object exists and the name is spelled correctly in the relation object.","steps":[]},"F0989":{"explanation":"The object refers to an object that was not found.","recommendation":"Make sure that referenced object exists and the name is spelled correctly in the relation object.","steps":[]},"F1011":{"explanation":"The object refers to an object that was not found.","recommendation":"Make sure that referenced object exists and the name is spelled correctly in the relation object.","steps":[]},"F1020":{"explanation":"The object refers to an object that was not found.","recommendation":"Make sure that referenced object exists and the name is spelled correctly in the relation object.","steps":[]},"F1056":{"explanation":"The object refers to an object that was not found.","recommendation":"Make sure that referenced object exists and the name is spelled correctly in the relation object.","steps":[]},"F1123":{"explanation":"The object refers to an object that was not found.","recommendation":"Make sure that referenced object exists and the name is spelled correctly in the relation object.","steps":[]},"F1186":{"explanation":"This fault is caused by a hardware programming failure","recommendation":"The system will periodically retry to program the hardware. If the failure is due to lack of hardware resources, free up resources by removing or simplifying existing configuration. One of the reasons for lack of hardware resources is exhaustion of VLANs in ToR. These hardware resources can be examined by looking at capacity dashboard under OPERATIONS tab. Please check entry against the number of VLANs in output of command show vlan summary issued at node where fault is generated to check whether it exceeds above advertised node capacity.","steps":[]},"F1296":{"explanation":"This fault occurs when vpc interface goes down while peer interface is also down.","recommendation":"Please verify the port connectivity.","steps":[]},"F1360":{"explanation":"This fault occurs when the operational state of the coop adjacency is down","recommendation":"To recover from this fault, try the following actions","steps":["Look at any configuration issues","Look at any connectivity issues","If the above actions did not resolve the issue, generate the show tech-support file and contact Cisco TAC."]},"F1394":{"explanation":"This fault occurs when a port is down and is in use for fabric","recommendation":"If you see this fault, take the following actions","steps":["Check the port connectivity","Administratively shut the port if the port is not in use","For mcp-loop-err-disable, this could be due to a loop in the network. Check the config to resolve any loops","If the above action did not resolve the issue, create a tech-support file and contact Cisco TAC."]},"F1451":{"explanation":"This fault occurs when psu is shut down","recommendation":"To recover from this fault, try the following actions","steps":["Connect a power supply to this PSU","If the above actions did not resolve the issue, create a show tech-support file and contact Cisco TAC"]},"F1543":{"explanation":"This fault occurs when a node is not reachable","recommendation":"If you see this fault, take the following action:","steps":["Check the connectivity of the node that cannot be reached.","Check if the node is powered up.","If the node is decommissioned, clean reboot the node manually as a workaround","If the above actions did not resolve the issue, create a show tech-support file and contact Cisco TAC."]},"F1606":{"explanation":"This fault is raised when issues are detected with portgroups learned from vCenter. E.g. missing EPg policy","recommendation":"If you see this fault, take the following actions:","steps":["Fix the issue by creating the policy based on the fault description","If the above actions did not resolve the issue, collect tech-support file and contact Cisco TAC."]},"F1651":{"explanation":"This fault occurs when export operation for techsupport or core files did not succeed.","recommendation":"If you see this fault, take the following actions:","steps":["look at techsupport status and figure out which IFC/node is erroring out.","Verify the destination it is trying to export data to is healthy/reachable","If the above action did not resolve the issue, contact Cisco TAC."]},"F1888":{"explanation":"This fault occurs when the native vlan is not configured on the interface but it is receiving MST (802.1s) BPDUs. It could lead to layer2 topology with a loop.","recommendation":"To recover from this fault, try the following actions","steps":["Configure native vlan on the interface","If the above actions did not resolve the issue, generate the show tech-support file and contact Cisco TAC."]},"F2330":{"explanation":"This fault occurs due to PIM is enabled on a layer 3 out that has external SVI interfaces.","recommendation":"If you see this fault, you may change the layer 3 out configure to get rid of the fault.","steps":[]},"F2409":{"explanation":"This fault occurs when there are specific configuration errors on a bridge domain, but the igmpsnoop is disabled.","recommendation":"If you see this fault, take the following actions:","steps":["For \"igmpsnoop is disabled on multicast enabled BD\" error, enable igmpsnoop (set adminSt in igmp:SnoopPol or disallow multicast (set property mcastAllow to \"false\")","If the above action did not resolve the issue, create a tech-support file and contact Cisco TAC"]},"F2740":{"explanation":"This fault occurs when port speed is configured to an invalid/unsupported value","recommendation":"To recover from this fault, correct speed in link-level policy used in TOR or change the speed as \"inherit\"","steps":[]},"F2840":{"explanation":"This fault is raised when ACI controller failed to update the properties of a VMware hypervisor.","recommendation":"If you see this fault, take the following actions:","steps":["Check in VCenter whether there is any faults raised for the Hypervisor in question and resolve the faults via VCenter","If the above actions did not resolve the issue, collect tech-support file and contact Cisco TAC."]},"F3254":{"explanation":"Plugin health is not OK.","recommendation":"If you see this fault, please raise a TAC case. Uninstall/Install App may help resolve the issue.","steps":[]},"F3634":{"explanation":"The object refers to an object that was not found.","recommendation":"Make sure that referenced object exists and the name is spelled correctly in the relation object.","steps":[]},"F3848":{"explanation":"This fault occurs when the Power Supply Unit is present and in powered down state","recommendation":"If you see this fault, take the following action:","steps":["power on the unit. make sure PSU is receiving power-supply","If the above action did not resolve the issue, create a show tech-support file and contact Cisco TAC."]},"F93337":{"explanation":"This fault is caused by \"memory usage current value\" statistical property crossing threshold level.","recommendation":"Check the values of \"memory usage\" statistical counter and either correct the conditions that cause the counter values to cross certain threshold levels, or adjust the threshold values in monitoring policies.","steps":[]}},"state":{},"recommended":{},"actionRecommended":false,"meta":{"runTime":"205.44137ms"}}},"admin":{"upgradeGroups":{"name":"Firmware Groups","state":{"hasNonRedundantAPICs":false,"hasNonRedundantVPCs":false,"hasNonRedundantSpines":true,"hasGracefulMaintSingleSpine":false,"hasMalformedVersionString":false},"recommended":{"hasNonRedundantAPICs":false,"hasNonRedundantVPCs":false,"hasNonRedundantSpines":false,"hasGracefulMaintSingleSpine":false,"hasMalformedVersionString":false},"actionRecommended":true,"descr":"Firmware group configuration checks","nonRedundantAPICs":null,"nonRedundantVPCNodes":null,"malformedVersions":null,"notes":null,"groupByNode":{"101":{"groupName":"LEAF-ODD","version":"15.2(3g)","graceful":false},"102":{"groupName":"LEAF-EVEN","version":"15.2(3g)","graceful":false},"103":{"groupName":"LEAF-ODD","version":"15.2(3g)","graceful":false},"104":{"groupName":"LEAF-EVEN","version":"15.2(3g)","graceful":false},"201":{"groupName":"SPINE_ODD","version":"15.2(3g)","graceful":false},"202":{"groupName":"SPINE-EVEN","version":"15.2(3g)","graceful":false}},"meta":{"runTime":"3.704107ms"}},"firmwareVersion":{"name":"Firmware Versions","descr":"Firmware version statistics","version":"5.2(3g)","apicVersion":"5.2(3g)","switchVersion":"5.2(3g)","state":{"hasMultipleVersions":false},"recommended":{"hasMultipleVersions":false},"versions":[],"actionRecommended":false,"meta":{"runTime":"3.815784ms"}}},"eol":{"apic":{"name":"APIC EoL Notices","descr":"APIC L1/M1 and L2/M2 EoL check","state":{"hasM1L1":false,"hasM2L2":true},"recommended":{"hasM1L1":false,"hasM2L2":false},"m1l1Notice":{"announcementDate":"10 May 2016","url":"https://www.cisco.com/c/en/us/products/collateral/cloud-systems-management/application-policy-infrastructure-controller-apic/eos-eol-notice-c51-737079.html"},"m2l2Notice":{"announcementDate":"16 Apr 2019","url":"https://www.cisco.com/c/en/us/products/collateral/cloud-systems-management/application-policy-infrastructure-controller-apic/eos-eol-notice-c51-742143.html"},"actionRecommended":true,"meta":{"runTime":"2.538559ms"}},"switch":{"name":"Switch EoL Notices","descr":"Switch EoL Check","state":{"hasEoL":true},"recommended":{"hasEoL":false},"actionRecommended":true,"eolDetails":{"N9K-C93180YC-EX":{"announcementDate":"August 9, 2021","url":"https://www.cisco.com/c/en/us/products/collateral/switches/nexus-9000-series-switches/n9k-c93180yc-c93108tc-ex.html","devices":[{"name":"DC1-LEAF-101","dn":"topology/pod-1/node-101"},{"name":"DC1-LEAF-102","dn":"topology/pod-1/node-102"}]}},"meta":{"runTime":"5.666684ms"}}},"apps":{"algosec":{"name":"AlgoSec App Check","state":{"installed":false},"recommended":{"installed":false},"actionRecommended":false,"descr":"AlgoSec app could contribute to CSCvv12524","meta":{"runTime":"3.38898ms"}}},"meta":{"customer":"","fabric":"","pid":"","region":"","timestamp":"2022-09-02T01:57:18+09:00","totalRunTime":"206.465263ms","version":"2.3.2"}}